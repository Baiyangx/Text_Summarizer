{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4106bb38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import torch\n",
    "from pytorchtools import EarlyStopping\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718dc587",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SWong7923\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579bb36f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('\\\\Users\\\\SWong7923\\\\PycharmProjects\\\\pythonProject2\\\\archive\\\\Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "420803d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e813654",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce55d73b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1279457b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         0\n",
       "ProductId                  0\n",
       "UserId                     0\n",
       "ProfileName               16\n",
       "HelpfulnessNumerator       0\n",
       "HelpfulnessDenominator     0\n",
       "Score                      0\n",
       "Time                       0\n",
       "Summary                   27\n",
       "Text                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e4d1f21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# reviews['Summary'].replace('',np.nan,inplace=True)\n",
    "reviews.dropna(subset=['Summary', 'Text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4340d604",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         0\n",
       "ProductId                  0\n",
       "UserId                     0\n",
       "ProfileName               16\n",
       "HelpfulnessNumerator       0\n",
       "HelpfulnessDenominator     0\n",
       "Score                      0\n",
       "Time                       0\n",
       "Summary                    0\n",
       "Text                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4878c4fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9a9dcdd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\",\n",
    "' american ':\n",
    "        [\n",
    "            'amerikan'\n",
    "        ],\n",
    "\n",
    "    ' adolf ':\n",
    "        [\n",
    "            'adolf'\n",
    "        ],\n",
    "\n",
    "\n",
    "    ' hitler ':\n",
    "        [\n",
    "            'hitler'\n",
    "        ],\n",
    "\n",
    "    ' fuck':\n",
    "        [\n",
    "            '(f)(u|[^a-z0-9 ])(c|[^a-z0-9 ])(k|[^a-z0-9 ])([^ ])*',\n",
    "            '(f)([^a-z]*)(u)([^a-z]*)(c)([^a-z]*)(k)',\n",
    "            ' f[!@#\\$%\\^\\&\\*]*u[!@#\\$%\\^&\\*]*k', 'f u u c',\n",
    "            '(f)(c|[^a-z ])(u|[^a-z ])(k)', r'f\\*',\n",
    "            'feck ', ' fux ', 'f\\*\\*', \n",
    "            'f\\-ing', 'f\\.u\\.', 'f###', ' fu ', 'f@ck', 'f u c k', 'f uck', 'f ck','fuk', 'wtf','fucck','f cking'\n",
    "        ],\n",
    "\n",
    "    ' ass ':\n",
    "        [\n",
    "            '[^a-z]ass ', '[^a-z]azz ', 'arrse', ' arse ', '@\\$\\$'\n",
    "                                                           '[^a-z]anus', ' a\\*s\\*s', '[^a-z]ass[^a-z ]',\n",
    "            'a[@#\\$%\\^&\\*][@#\\$%\\^&\\*]', '[^a-z]anal ', 'a s s'\n",
    "        ],\n",
    "\n",
    "    ' asshole ':\n",
    "        [\n",
    "            ' a[s|z]*wipe', 'a[s|z]*[w]*h[o|0]+[l]*e', '@\\$\\$hole', 'ass hole'\n",
    "        ],\n",
    "\n",
    "    ' bitch ':\n",
    "        [\n",
    "            'b[w]*i[t]*ch', 'b!tch',\n",
    "            'bi\\+ch', 'b!\\+ch', '(b)([^a-z]*)(i)([^a-z]*)(t)([^a-z]*)(c)([^a-z]*)(h)',\n",
    "            'biatch', 'bi\\*\\*h', 'bytch', 'b i t c h','beetch'\n",
    "        ],\n",
    "\n",
    "    ' bastard ':\n",
    "        [\n",
    "            'ba[s|z]+t[e|a]+rd'\n",
    "        ],\n",
    "\n",
    "    ' transgender':\n",
    "        [\n",
    "            'transgender','trans gender'\n",
    "        ],\n",
    "\n",
    "    ' gay ':\n",
    "        [\n",
    "            'gay'\n",
    "        ],\n",
    "\n",
    "    ' cock ':\n",
    "        [\n",
    "            '[^a-z]cock', 'c0ck', '[^a-z]cok ', 'c0k', '[^a-z]cok[^aeiou]', ' cawk',\n",
    "            '(c)([^a-z ])(o)([^a-z ]*)(c)([^a-z ]*)(k)', 'c o c k'\n",
    "        ],\n",
    "\n",
    "    ' dick ':\n",
    "        [\n",
    "            ' dick[^aeiou]', 'deek', 'd i c k','diick '\n",
    "        ],\n",
    "\n",
    "    ' suck ':\n",
    "        [\n",
    "            'sucker', '(s)([^a-z ]*)(u)([^a-z ]*)(c)([^a-z ]*)(k)', 'sucks', '5uck', 's u c k'\n",
    "        ],\n",
    "\n",
    "    ' cunt ':\n",
    "        [\n",
    "            'cunt', 'c u n t'\n",
    "        ],\n",
    "\n",
    "    ' bullshit ':\n",
    "        [\n",
    "            'bullsh\\*t', 'bull\\$hit','bs'\n",
    "        ],\n",
    "\n",
    "    ' homosexual':\n",
    "        [\n",
    "            'homo sexual','homosex'\n",
    "        ],\n",
    "\n",
    "    ' jerk ':\n",
    "        [\n",
    "            'jerk'\n",
    "        ],\n",
    "\n",
    "    ' idiot ':\n",
    "        [\n",
    "            'i[d]+io[t]+', '(i)([^a-z ]*)(d)([^a-z ]*)(i)([^a-z ]*)(o)([^a-z ]*)(t)', 'idiots', 'i d i o t'\n",
    "        ],\n",
    "\n",
    "    ' dumb ':\n",
    "        [\n",
    "            '(d)([^a-z ]*)(u)([^a-z ]*)(m)([^a-z ]*)(b)'\n",
    "        ],\n",
    "\n",
    "    ' shit ':\n",
    "        [\n",
    "            'shitty', '(s)([^a-z ]*)(h)([^a-z ]*)(i)([^a-z ]*)(t)', 'shite', '\\$hit', 's h i t'\n",
    "        ],\n",
    "\n",
    "    ' shithole ':\n",
    "        [\n",
    "            'shythole','shit hole'\n",
    "        ],\n",
    "\n",
    "    ' retard ':\n",
    "        [\n",
    "            'returd', 'retad', 'retard', 'wiktard', 'wikitud'\n",
    "        ],\n",
    "\n",
    "    ' rape ':\n",
    "        [\n",
    "            ' raped'\n",
    "        ],\n",
    "\n",
    "    ' dumbass':\n",
    "        [\n",
    "            'dumb ass', 'dubass'\n",
    "        ],\n",
    "\n",
    "    ' asshead':\n",
    "        [\n",
    "            'butthead', 'ass head'\n",
    "        ],\n",
    "\n",
    "    ' sex ':\n",
    "        [\n",
    "            's3x', 'sexuality',\n",
    "        ],\n",
    "\n",
    "\n",
    "    ' nigger ':\n",
    "        [\n",
    "            'nigger', 'ni[g]+a', ' nigr ', 'negrito', 'niguh', 'n3gr', 'n i g g e r'\n",
    "        ],\n",
    "\n",
    "    ' shut the fuck up':\n",
    "        [\n",
    "            'stfu'\n",
    "        ],\n",
    "\n",
    "    ' pussy ':\n",
    "        [\n",
    "            'pussy[^c]', 'pusy', 'pussi[^l]', 'pusses'\n",
    "        ],\n",
    "\n",
    "    ' faggot ':\n",
    "        [\n",
    "            'faggot', ' fa[g]+[s]*[^a-z ]', 'fagot', 'f a g g o t', 'faggit',\n",
    "            '(f)([^a-z ]*)(a)([^a-z ]*)([g]+)([^a-z ]*)(o)([^a-z ]*)(t)', 'fau[g]+ot', 'fae[g]+ot',\n",
    "        ],\n",
    "\n",
    "    ' motherfucker':\n",
    "        [\n",
    "            ' motha ', ' motha f', ' mother f', 'motherucker', 'mother fucker'\n",
    "        ],\n",
    "\n",
    "    ' whore ':\n",
    "        [\n",
    "            'wh\\*\\*\\*', 'w h o r e'\n",
    "        ],\n",
    "    \" White's \" : 'white'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "518a3fdc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace contractions with their longer forms \n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'<br >', '', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05cfd789",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries are complete.\n",
      "Texts are complete.\n"
     ]
    }
   ],
   "source": [
    "clean_summaries = []\n",
    "for summary in reviews.Summary:\n",
    "    if not isinstance(summary, str):\n",
    "        print(summary)\n",
    "        continue\n",
    "    clean_summaries.append(clean_text(summary, remove_stopwords=False))\n",
    "print(\"Summaries are complete.\")\n",
    "\n",
    "clean_texts = []\n",
    "for text in reviews.Text:\n",
    "    clean_texts.append(clean_text(text))\n",
    "print(\"Texts are complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87ca2c55",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Review # 16\n",
      "Summary:  lots of twizzlers  just what you expect \n",
      "Content:  daughter loves twizzlers shipment six pounds really hit spot exactly would expect six packages strawberry twizzlers\n",
      "\n",
      "Clean Review # 17\n",
      "Summary:  poor taste\n",
      "Content:  love eating good watching tv looking movies sweet like transfer zip lock baggie stay fresh take time eating\n",
      "\n",
      "Clean Review # 18\n",
      "Summary:  love it \n",
      "Content:  satisfied twizzler purchase shared others enjoyed definitely ordering\n",
      "\n",
      "Clean Review # 19\n",
      "Summary:  great sweet candy \n",
      "Content:  twizzlers strawberry childhood favorite candy made lancaster pennsylvania candies inc one oldest confectionery firms united states subsidiary hershey company company established 1845 young smylie also make apple licorice twists green color blue raspberry licorice twists like all<br ><br >i keep dry cool place recommended put fridge according guinness book records longest licorice twist ever made measured 1 200 feet 370 weighted 100 pounds 45 kg made candies inc record breaking twist became guinness world record july 19 1998 product kosher thank\n",
      "\n",
      "Clean Review # 20\n",
      "Summary:  home delivered twizlers\n",
      "Content:  candy delivered fast purchased reasonable price home bound unable get store perfect\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect the cleaned summaries and texts to ensure they have been cleaned well\n",
    "for i in range(15,20):\n",
    "    print(\"Clean Review #\",i+1)\n",
    "    print(\"Summary: \",clean_summaries[i])\n",
    "    print(\"Content: \",clean_texts[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bc29f07",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_words(count_dict, text):\n",
    "    '''Count the number of occurrences of each word in a set of text'''\n",
    "    for sentence in text:\n",
    "        for word in sentence.split():\n",
    "            if word not in count_dict:\n",
    "                count_dict[word] = 1\n",
    "            else:\n",
    "                count_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beae712a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary: 132887\n"
     ]
    }
   ],
   "source": [
    "word_counts = {}\n",
    "\n",
    "count_words(word_counts, clean_summaries)\n",
    "count_words(word_counts, clean_texts)\n",
    "            \n",
    "print(\"Size of Vocabulary:\", len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f11e83a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 417195\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('\\\\Users\\\\SWong7923\\\\PycharmProjects\\\\pythonProject2\\\\archive\\\\numberbatch-en.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "print('Word embeddings:', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87f3cff2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words missing from CN: 3870\n",
      "Percent of words that are missing from vocabulary: 2.91%\n"
     ]
    }
   ],
   "source": [
    "# Find the number of words that are missing from CN, and are used more than our threshold.\n",
    "missing_words = 0\n",
    "threshold = 20\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    if count > threshold:\n",
    "        if word not in embeddings_index:\n",
    "            missing_words += 1\n",
    "            \n",
    "missing_ratio = round(missing_words/len(word_counts),4)*100\n",
    "            \n",
    "print(\"Number of words missing from CN:\", missing_words)\n",
    "print(\"Percent of words that are missing from vocabulary: {}%\".format(missing_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96ef93bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words: 132887\n",
      "Number of words we will use: 59595\n",
      "Percent of words we will use: 44.85%\n"
     ]
    }
   ],
   "source": [
    "# Limit the vocab that we will use to words that appear ≥ threshold or are in GloVe\n",
    "\n",
    "#dictionary to convert words to integers\n",
    "vocab_to_int = {} \n",
    "\n",
    "value = 0\n",
    "for word, count in word_counts.items():\n",
    "    if count >= threshold or word in embeddings_index:\n",
    "        vocab_to_int[word] = value\n",
    "        value += 1\n",
    "\n",
    "# Special tokens that will be added to our vocab\n",
    "codes = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]   \n",
    "\n",
    "# Add codes to vocab\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = len(vocab_to_int)\n",
    "\n",
    "# Dictionary to convert integers to words\n",
    "int_to_vocab = {}\n",
    "for word, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = word\n",
    "\n",
    "usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
    "\n",
    "print(\"Total number of unique words:\", len(word_counts))\n",
    "print(\"Number of words we will use:\", len(vocab_to_int))\n",
    "print(\"Percent of words we will use: {}%\".format(usage_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad3a9c99",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59595\n"
     ]
    }
   ],
   "source": [
    "# Need to use 300 for embedding dimensions to match CN's vectors.\n",
    "embedding_dim = 300\n",
    "nb_words = len(vocab_to_int)\n",
    "\n",
    "# Create matrix with default values of zero\n",
    "word_embedding_matrix = np.zeros((nb_words, embedding_dim), dtype=np.float32)\n",
    "for word, i in vocab_to_int.items():\n",
    "    if word in embeddings_index:\n",
    "        word_embedding_matrix[i] = embeddings_index[word]\n",
    "    else:\n",
    "        # If word not in CN, create a random embedding for it\n",
    "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "        embeddings_index[word] = new_embedding\n",
    "        word_embedding_matrix[i] = new_embedding\n",
    "\n",
    "# Check if value matches len(vocab_to_int)\n",
    "print(len(word_embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b352deb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_ints(text, word_count, unk_count):\n",
    "    '''Convert words in text to an integer(the index of words in vocabulary).\n",
    "       If word is not in vocab_to_int, use UNK's integer.\n",
    "       Total the number of words and UNKs.\n",
    "       Add EOS token to the end of texts'''\n",
    "    ints = []\n",
    "    for sentence in text:\n",
    "        sentence_ints = [vocab_to_int[\"<GO>\"]]\n",
    "        for word in sentence.split():\n",
    "            word_count += 1\n",
    "            if word in vocab_to_int:\n",
    "                sentence_ints.append(vocab_to_int[word])\n",
    "            else:\n",
    "                sentence_ints.append(vocab_to_int[\"<UNK>\"])\n",
    "                unk_count += 1\n",
    "       \n",
    "        sentence_ints.append(vocab_to_int[\"<EOS>\"])\n",
    "        ints.append(sentence_ints)\n",
    "    return ints, word_count, unk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87b0e5fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in headlines: 25680389\n",
      "Total number of UNKs in headlines: 192248\n",
      "Percent of words that are UNK: 0.75%\n"
     ]
    }
   ],
   "source": [
    "# Apply convert_to_ints to clean_summaries and clean_texts\n",
    "word_count = 0\n",
    "unk_count = 0\n",
    "\n",
    "int_summaries, word_count, unk_count = convert_to_ints(clean_summaries, word_count, unk_count)\n",
    "int_texts, word_count, unk_count = convert_to_ints(clean_texts, word_count, unk_count)\n",
    "\n",
    "unk_percent = round(unk_count/word_count,4)*100\n",
    "\n",
    "print(\"Total number of words in headlines:\", word_count)\n",
    "print(\"Total number of UNKs in headlines:\", unk_count)\n",
    "print(\"Percent of words that are UNK: {}%\".format(unk_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23cbbca6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_lengths(text):\n",
    "    '''Create a data frame of the sentence lengths from a text'''\n",
    "    lengths = []\n",
    "    for sentence in text:\n",
    "        lengths.append(len(sentence))\n",
    "    return pd.DataFrame(lengths, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "037ac585",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries:\n",
      "              counts\n",
      "count  568427.000000\n",
      "mean        6.181613\n",
      "std         2.657912\n",
      "min         2.000000\n",
      "25%         4.000000\n",
      "50%         6.000000\n",
      "75%         7.000000\n",
      "max        50.000000\n",
      "\n",
      "Texts:\n",
      "              counts\n",
      "count  568427.000000\n",
      "mean       42.996376\n",
      "std        42.520534\n",
      "min         2.000000\n",
      "25%        19.000000\n",
      "50%        30.000000\n",
      "75%        51.000000\n",
      "max      2086.000000\n"
     ]
    }
   ],
   "source": [
    "lengths_summaries = create_lengths(int_summaries)\n",
    "lengths_texts = create_lengths(int_texts)\n",
    "\n",
    "print(\"Summaries:\")\n",
    "print(lengths_summaries.describe())\n",
    "print()\n",
    "print(\"Texts:\")\n",
    "print(lengths_texts.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d889f84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.0\n",
      "116.0\n",
      "208.0\n"
     ]
    }
   ],
   "source": [
    "# Inspect the length of texts\n",
    "print(np.percentile(lengths_texts.counts, 90))\n",
    "print(np.percentile(lengths_texts.counts, 95))\n",
    "print(np.percentile(lengths_texts.counts, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ab2bb32",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "11.0\n",
      "15.0\n"
     ]
    }
   ],
   "source": [
    "# Inspect the length of summaries\n",
    "print(np.percentile(lengths_summaries.counts, 90))\n",
    "print(np.percentile(lengths_summaries.counts, 95))\n",
    "print(np.percentile(lengths_summaries.counts, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15d9d041",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def unk_counter(sentence):\n",
    "    '''Counts the number of time UNK appears in a sentence.'''\n",
    "    unk_count = 0\n",
    "    for word in sentence:\n",
    "        if word == vocab_to_int[\"<UNK>\"]:\n",
    "            unk_count += 1\n",
    "    return unk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a95b8643",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472193\n",
      "472193\n"
     ]
    }
   ],
   "source": [
    "# takes a long time  , this is normal\n",
    "\n",
    "# Sort the summaries and texts by the length of the texts, shortest to longest\n",
    "# Limit the length of summaries and texts based on the min and max ranges.\n",
    "# Remove reviews that include too many UNKs\n",
    "\n",
    "sorted_summaries = []\n",
    "sorted_texts = []\n",
    "max_text_length = 84\n",
    "max_summary_length = 13\n",
    "min_length = 2\n",
    "unk_text_limit = 1\n",
    "unk_summary_limit = 0\n",
    "\n",
    "for length in range(min(lengths_texts.counts), max_text_length): \n",
    "    for count, words in enumerate(int_summaries):\n",
    "        if (len(int_summaries[count]) >= min_length and\n",
    "            len(int_summaries[count]) <= max_summary_length and\n",
    "            len(int_texts[count]) >= min_length and\n",
    "            unk_counter(int_summaries[count]) <= unk_summary_limit and\n",
    "            unk_counter(int_texts[count]) <= unk_text_limit and\n",
    "            length == len(int_texts[count])\n",
    "           ):\n",
    "            sorted_summaries.append(int_summaries[count])\n",
    "            sorted_texts.append(int_texts[count])\n",
    "        \n",
    "# Compare lengths to ensure they match\n",
    "print(len(sorted_summaries))\n",
    "print(len(sorted_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4ef736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_texts[-100:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24ab6377",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f43e270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shortest text length: 24\n",
      "The longest text length: 83\n"
     ]
    }
   ],
   "source": [
    "# Subset the data for training\n",
    "start = 200000\n",
    "end = start + 300000\n",
    "sorted_summaries_short = sorted_summaries[start:end]\n",
    "sorted_texts_short = sorted_texts[start:end]\n",
    "print(\"The shortest text length:\", len(sorted_texts_short[0]))\n",
    "print(\"The longest text length:\",len(sorted_texts_short[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6ac3040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<GO> usually buy go go brown rice convenience time cook use rice noticeable change pleasing smell taste hybrid rice love high quality rice <EOS>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([int_to_vocab[i] for i in sorted_texts_short[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85cefd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(sorted_texts_short) * 0.9)\n",
    "val_size = len(sorted_texts_short) - train_size\n",
    "zipped = list(zip(sorted_texts_short, sorted_summaries_short))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(zipped, [train_size,val_size])\n",
    "text_train, summ_train = zip(*train_dataset)\n",
    "text_val, summ_val = zip(*val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a57cac12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<GO> it is not too good to be true <EOS>'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([int_to_vocab[i] for i in summ_train[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28580eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<GO> greatest low fat organic snack ever tasted taste like pumpernickel bread holidays love haves 1 5 grams fat 14 pretzels hearty snack say enough great things snack <EOS>'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([int_to_vocab[i] for i in text_train[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "972b7b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44, 76, 46, 29, 24, 79, 24, 43, 75, 41]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x)for x in text_train[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "121bd237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_argsort(seq):\n",
    "    return sorted(range(len(seq)), key=lambda x: len(seq[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c38e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index = len_argsort(text_train)\n",
    "text_train = [text_train[i] for i in sorted_index]\n",
    "summ_train = [summ_train[i] for i in sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "185efe81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x)for x in text_train[-2:-1]] # 24 - 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cf30393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO> bought elderly cat health problems needs gain weight coincidentally new kitten well 4 cats love food none like wet food forever food <EOS>\n",
      "<GO> approved of by all my felines <EOS>\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "print(\" \".join([int_to_vocab[i] for i in text_train[k]]))\n",
    "print(\" \".join([int_to_vocab[i] for i in summ_train[k]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37faf98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按索引划分batch，返回的每个batch中存的是index\n",
    "def get_minibatches(n, minibatch_size, shuffle=True):\n",
    "    idx_list = np.arange(0, n, minibatch_size)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx_list)\n",
    "    minibatches = []\n",
    "    for idx in idx_list:\n",
    "        minibatches.append(np.arange(idx, min(idx+minibatch_size, n)))\n",
    "    return minibatches      # 这个会返回多批连着的bath_size个索引  \n",
    "#get_minibatches(len(train_en), 32)\n",
    "\n",
    "# 这个函数是在做数据预处理， 由于每个句子都不是一样长， 所以通过这个函数就可以把句子进行补齐， 不够长的在句子后面添加0\n",
    "def prepare_data(seqs):\n",
    "    lengths = [len(seq) for seq in seqs]    # 得到每个句子的长度\n",
    "    n_samples = len(seqs)       # 得到一共有多少个句子\n",
    "    max_len = np.max(lengths)              # 找出最大的句子长度\n",
    "    \n",
    "    x = np.zeros((n_samples, max_len)).astype('int32')    # 按照最大句子长度生成全0矩阵\n",
    "    x_lengths = np.array(lengths).astype('int32')\n",
    "    for idx, seq in enumerate(seqs):        # 把有句子的位置填充进去\n",
    "        x[idx, :lengths[idx]] = seq\n",
    "    return x, x_lengths      # x_mask\n",
    "\n",
    "def gen_examples(en_sentences, cn_sentences, batch_size):\n",
    "    minibatches = get_minibatches(len(en_sentences), batch_size)   # 得到batch个索引\n",
    "    all_ex = []\n",
    "    for minibatch in minibatches:   # 每批数据的索引\n",
    "        mb_en_sentences = [en_sentences[t] for t in minibatch]   # 取数据\n",
    "        mb_cn_sentences = [cn_sentences[t] for t in minibatch]  # 取数据\n",
    "        mb_x, mb_x_len = prepare_data(mb_en_sentences) # 填充成一样的长度， 但是要记录一下句子的真实长度， 这个在后面输入网络的时候得用\n",
    "        mb_y, mb_y_len = prepare_data(mb_cn_sentences)\n",
    "        all_ex.append((mb_x, mb_x_len, mb_y, mb_y_len))\n",
    "    return all_ex\n",
    "\n",
    "batch_size = 64\n",
    "train_data = gen_examples(text_train, summ_train, batch_size)   # 产生训练集\n",
    "random.shuffle(train_data)\n",
    "dev_data = gen_examples(text_val, summ_val, batch_size)   # 产生验证集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f9b44fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 46) (64,) (64, 11) (64,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data[1][0].shape, train_data[1][1].shape, train_data[1][2].shape, train_data[1][3].shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b79c5500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, enc_hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(enc_hidden_size * 2, dec_hidden_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        sorted_len, sorted_idx = lengths.sort(0, descending=True)\n",
    "        x_sorted = x[sorted_idx.long()]\n",
    "        embedded = self.dropout(self.embed(x_sorted))\n",
    "        \n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, sorted_len.long().cpu().data.numpy(), batch_first=True)\n",
    "        packed_out, hid = self.rnn(packed_embedded)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "        out = out[original_idx.long()].contiguous() # [batch_size, seq_len, num_directions=2 * enc_hidden_size]\n",
    "        hid = hid[:, original_idx.long()].contiguous() # [num_layers=1 * num_directions=2, batch_size, enc_hidden_size]\n",
    "        \n",
    "        # hid[m] [batch_size, enc_hidden_size]\n",
    "        hid = torch.cat([hid[-2], hid[-1]], dim=1) # [batch_size, enc_hidden_size*2]\n",
    "        hid = torch.tanh(self.fc(hid)).unsqueeze(0) # [1,batch_size,dec_hidden_size]\n",
    "\n",
    "        return out, hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30bdc0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_size, dec_hidden_size):\n",
    "        super().__init__()\n",
    "        self.enc_hidden_size = enc_hidden_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "        self.linear_in = nn.Linear(enc_hidden_size*2, dec_hidden_size, bias=False)\n",
    "        self.linear_out = nn.Linear(enc_hidden_size*2 + dec_hidden_size, dec_hidden_size)\n",
    "        \n",
    "    def forward(self, output, context, mask):\n",
    "        # output: [batch_size, output_len, dec_hidden_size]\n",
    "        # context: [batch_size, context_len, 2*enc_hidden_size]\n",
    "    \n",
    "        batch_size = output.size(0)\n",
    "        output_len = output.size(1)\n",
    "        input_len = context.size(1)\n",
    "        \n",
    "        context_in = self.linear_in(context.view(batch_size*input_len, -1)).view(                \n",
    "            batch_size, input_len, -1) # batch_size, context_len, dec_hidden_size\n",
    "        \n",
    "        # context_in.transpose(1,2): batch_size, dec_hidden_size, context_len \n",
    "        # output: batch_size, output_len, dec_hidden_size\n",
    "        attn = torch.bmm(output, context_in.transpose(1,2))  # batch_size, output_len, context_len\n",
    "\n",
    "        # mask必须是一个 ByteTensor 而且shape必须和 attn 一样 并且元素只能是 0或者1\n",
    "        # tensor.data.masked_fill(mask,value):将 mask中为1的 元素所在的索引，在tensor中相同的的索引处替换为 value\n",
    "        # 将不是单词的位置设成很小的数,使softmax不受非单词的元素影响\n",
    "        attn.data.masked_fill(mask, -1e6)\n",
    "\n",
    "        attn = F.softmax(attn, dim=2)  # batch_size, output_len, context_len\n",
    "\n",
    "        context = torch.bmm(attn, context) \n",
    "        # batch_size, output_len, 2*enc_hidden_size\n",
    "        \n",
    "        output = torch.cat((context, output), dim=2) # batch_size, output_len, enc_hidden_size*2 + dec_hidden_size\n",
    "\n",
    "        output = output.view(batch_size*output_len, -1)\n",
    "        output = torch.tanh(self.linear_out(output))\n",
    "        output = output.view(batch_size, output_len, -1) # batch_size, output_len, dec_hidden_size\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6b9cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.attention = Attention(enc_hidden_size, dec_hidden_size)\n",
    "        self.rnn = nn.GRU(embed_size, dec_hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(dec_hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def create_mask(self, y_len, x_len):\n",
    "        max_y_len = y_len.max()\n",
    "        max_x_len = x_len.max()\n",
    "        x_mask = torch.arange(max_x_len, device=x_len.device)[None, :] < x_len[:, None] # [batch_size,max_x_len]\n",
    "        y_mask = torch.arange(max_y_len, device=x_len.device)[None, :] < y_len[:, None] # [batch_size,max_y_len]\n",
    "        # 以1个batch的1句话为例(英文共n个字),取其中一个中文字(矩阵的某行),英文前n个字(列)值为0,为0代表有效\n",
    "        # ~代表bool变量取反\n",
    "        mask = (~(y_mask[:, :, None] * x_mask[:, None, :])).byte() # [batch_size,max_y_len,max_x_len]\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, ctx, ctx_lengths, y, y_lengths, hid):\n",
    "        sorted_len, sorted_idx = y_lengths.sort(0, descending=True)\n",
    "        y_sorted = y[sorted_idx.long()] # [batch_size,y_len,vocab_size]\n",
    "        hid = hid[:, sorted_idx.long()]\n",
    "        \n",
    "        y_sorted = self.dropout(self.embed(y_sorted)) # batch_size, 中文seq_length, embed_size\n",
    "\n",
    "        packed_seq = nn.utils.rnn.pack_padded_sequence(y_sorted, sorted_len.long().cpu().data.numpy(), batch_first=True)\n",
    "        out, hid = self.rnn(packed_seq, hid)\n",
    "        unpacked, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True) # [batch_size,中文seq_len,dec_hidden_size]\n",
    "        \n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "        \n",
    "        output_seq = unpacked[original_idx.long()].contiguous() # [batch_size,中文seq_len,dec_hidden_size]\n",
    "        \n",
    "        hid = hid[:, original_idx.long()].contiguous() # [1,batch_size,dec_hidden_size]\n",
    "\n",
    "        mask = self.create_mask(y_lengths, ctx_lengths) # [batch_size,中文seq_len,英文seq_len]\n",
    "\n",
    "        # output [batch_size, 中文seq_len, dec_hidden_size]\n",
    "        # attn [batch_size,中文seq_len,英文seq_len]\n",
    "        output, attn = self.attention(output_seq, ctx, mask)\n",
    "        \n",
    "        output = F.log_softmax(self.out(output), dim=-1) # batch_size, output_len, vocab_size\n",
    "        \n",
    "        return output, hid, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f6686ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, x, x_lengths, y, y_lengths):\n",
    "        encoder_out, hid = self.encoder(x, x_lengths)\n",
    "        output, hid, attn = self.decoder(ctx=encoder_out, \n",
    "                    ctx_lengths=x_lengths,\n",
    "                    y=y,\n",
    "                    y_lengths=y_lengths,\n",
    "                    hid=hid)\n",
    "        return output\n",
    "    \n",
    "    def translate(self, x, x_lengths, y, max_length=100):\n",
    "        encoder_out, hid = self.encoder(x, x_lengths)\n",
    "        preds = []\n",
    "        batch_size = x.shape[0]\n",
    "        attns = []\n",
    "        for i in range(max_length):\n",
    "            output, hid, attn = self.decoder(ctx=encoder_out, \n",
    "                    ctx_lengths=x_lengths,\n",
    "                    y=y,\n",
    "                    y_lengths=torch.ones(batch_size).long().to(y.device),\n",
    "                    hid=hid)\n",
    "            y = output.max(2)[1].view(batch_size, 1)\n",
    "            preds.append(y)\n",
    "            attns.append(attn)\n",
    "        return torch.cat(preds, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5c1000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked cross entropy loss\n",
    "class LanguageModelCriterion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LanguageModelCriterion, self).__init__()\n",
    "    \n",
    "    def forward(self, input, target, mask):\n",
    "        # input: [batch_size, seq_len, vocab_size]    每个单词的可能性\n",
    "        input = input.contiguous().view(-1, input.size(2))   # [batch_size*seq_len-1, vocab_size] 将input的batch_size和seq_len合并，再计算loss\n",
    "        target = target.contiguous().view(-1, 1)    #  [batch_size*seq_len-1, 1] # target里dim=1存的是正确summary 的index\n",
    "        \n",
    "        mask = mask.contiguous().view(-1, 1)   # [batch_size*seq_len-1, 1]\n",
    "        output = -input.gather(1, target) * mask # 在每个vocab_size维度取正确单词的索引， 但是里面有很多是填充进去的， 所以mask去掉这些填充的， \n",
    "        output = torch.sum(output) / torch.sum(mask)\n",
    "        \n",
    "        return output  # [batch_size*seq_len-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cdef7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dropout = 0.2\n",
    "hidden_size = 100\n",
    "embed_size = 100\n",
    "encoder = Encoder(vocab_size=len(word_embedding_matrix), embed_size=embed_size, enc_hidden_size=hidden_size, dec_hidden_size=hidden_size,)\n",
    "decoder = Decoder(vocab_size=len(word_embedding_matrix), embed_size=embed_size, enc_hidden_size=hidden_size, dec_hidden_size=hidden_size,)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "model = model.to(device)\n",
    "loss_fn = LanguageModelCriterion().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d774435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/50] train_loss: 4.13072 valid_loss: 3.97102\n",
      "Validation loss decreased (inf --> 3.971024).  Saving model ...\n",
      "[ 2/50] train_loss: 3.81447 valid_loss: 3.78429\n",
      "Validation loss decreased (3.971024 --> 3.784292).  Saving model ...\n",
      "[ 3/50] train_loss: 3.61617 valid_loss: 3.66755\n",
      "Validation loss decreased (3.784292 --> 3.667548).  Saving model ...\n",
      "[ 4/50] train_loss: 3.47153 valid_loss: 3.58305\n",
      "Validation loss decreased (3.667548 --> 3.583047).  Saving model ...\n",
      "[ 5/50] train_loss: 3.35908 valid_loss: 3.52305\n",
      "Validation loss decreased (3.583047 --> 3.523053).  Saving model ...\n",
      "[ 6/50] train_loss: 3.26630 valid_loss: 3.47380\n",
      "Validation loss decreased (3.523053 --> 3.473801).  Saving model ...\n",
      "[ 7/50] train_loss: 3.18794 valid_loss: 3.43626\n",
      "Validation loss decreased (3.473801 --> 3.436259).  Saving model ...\n",
      "[ 8/50] train_loss: 3.12061 valid_loss: 3.40811\n",
      "Validation loss decreased (3.436259 --> 3.408108).  Saving model ...\n",
      "[ 9/50] train_loss: 3.06018 valid_loss: 3.37973\n",
      "Validation loss decreased (3.408108 --> 3.379729).  Saving model ...\n",
      "[10/50] train_loss: 3.00622 valid_loss: 3.36142\n",
      "Validation loss decreased (3.379729 --> 3.361416).  Saving model ...\n",
      "[11/50] train_loss: 2.95691 valid_loss: 3.34265\n",
      "Validation loss decreased (3.361416 --> 3.342647).  Saving model ...\n",
      "[12/50] train_loss: 2.91178 valid_loss: 3.32825\n",
      "Validation loss decreased (3.342647 --> 3.328250).  Saving model ...\n",
      "[13/50] train_loss: 2.87075 valid_loss: 3.31066\n",
      "Validation loss decreased (3.328250 --> 3.310656).  Saving model ...\n",
      "[14/50] train_loss: 2.83217 valid_loss: 3.30066\n",
      "Validation loss decreased (3.310656 --> 3.300659).  Saving model ...\n",
      "[15/50] train_loss: 2.79772 valid_loss: 3.28780\n",
      "Validation loss decreased (3.300659 --> 3.287796).  Saving model ...\n",
      "[16/50] train_loss: 2.76392 valid_loss: 3.28162\n",
      "Validation loss decreased (3.287796 --> 3.281622).  Saving model ...\n",
      "[17/50] train_loss: 2.73313 valid_loss: 3.26959\n",
      "Validation loss decreased (3.281622 --> 3.269589).  Saving model ...\n",
      "[18/50] train_loss: 2.70284 valid_loss: 3.26619\n",
      "Validation loss decreased (3.269589 --> 3.266193).  Saving model ...\n",
      "[19/50] train_loss: 2.67517 valid_loss: 3.25696\n",
      "Validation loss decreased (3.266193 --> 3.256957).  Saving model ...\n",
      "[20/50] train_loss: 2.64848 valid_loss: 3.25496\n",
      "Validation loss decreased (3.256957 --> 3.254965).  Saving model ...\n",
      "[21/50] train_loss: 2.62370 valid_loss: 3.24914\n",
      "Validation loss decreased (3.254965 --> 3.249145).  Saving model ...\n",
      "[22/50] train_loss: 2.59938 valid_loss: 3.24344\n",
      "Validation loss decreased (3.249145 --> 3.243440).  Saving model ...\n",
      "[23/50] train_loss: 2.57603 valid_loss: 3.24403\n",
      "EarlyStopping counter: 1 out of 5\n",
      "[24/50] train_loss: 2.57640 valid_loss: 3.24213\n",
      "Validation loss decreased (3.243440 --> 3.242130).  Saving model ...\n",
      "[25/50] train_loss: 2.55394 valid_loss: 3.24149\n",
      "Validation loss decreased (3.242130 --> 3.241488).  Saving model ...\n",
      "[26/50] train_loss: 2.53369 valid_loss: 3.23951\n",
      "Validation loss decreased (3.241488 --> 3.239514).  Saving model ...\n",
      "[27/50] train_loss: 2.51335 valid_loss: 3.23448\n",
      "Validation loss decreased (3.239514 --> 3.234477).  Saving model ...\n",
      "[28/50] train_loss: 2.49301 valid_loss: 3.23287\n",
      "Validation loss decreased (3.234477 --> 3.232865).  Saving model ...\n",
      "[29/50] train_loss: 2.47552 valid_loss: 3.23200\n",
      "Validation loss decreased (3.232865 --> 3.231998).  Saving model ...\n",
      "[30/50] train_loss: 2.45839 valid_loss: 3.23239\n",
      "EarlyStopping counter: 1 out of 5\n",
      "[31/50] train_loss: 2.45804 valid_loss: 3.23376\n",
      "EarlyStopping counter: 2 out of 5\n",
      "[32/50] train_loss: 2.45803 valid_loss: 3.23360\n",
      "EarlyStopping counter: 3 out of 5\n",
      "[33/50] train_loss: 2.45855 valid_loss: 3.23416\n",
      "EarlyStopping counter: 4 out of 5\n",
      "[34/50] train_loss: 2.45693 valid_loss: 3.23331\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "# 定义训练和验证函数\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "#Please see the link below to learn about early stopping\n",
    "#https://towardsdatascience.com/a-practical-introduction-to-early-stopping-in-machine-learning-550ac88bc8fd \n",
    "min_val_loss = 100\n",
    "early_stop = False\n",
    "def evaluate(model, data):\n",
    "    model.eval()\n",
    "    total_num_words = total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for it, (mb_x, mb_x_len, mb_y, mb_y_len) in enumerate(data):\n",
    "            mb_x = torch.from_numpy(mb_x).to(device).long()    # 这个是一个batch的英文句子 大小是[batch_size, seq_len]\n",
    "            mb_x_len = torch.from_numpy(mb_x_len).to(device).long()    # 每个句子的长度\n",
    "            mb_input = torch.from_numpy(mb_y[:, :-1]).to(device).long()  # decoder的输入，训练的时候是整个summary（带<GO>）\n",
    "            mb_output = torch.from_numpy(mb_y[:, 1:]).to(device).long()   # 解码器那边的输出  [batch_size, seq_len-1]去掉<GO>\n",
    "            mb_y_len = torch.from_numpy(mb_y_len-1).to(device).long()  # 这个减去1， 去掉初始符号 [batch_size, seq_len-1]\n",
    "            mb_y_len[mb_y_len<=0] =  1   # 以防出错，防止trainset里面的summary长度被记为0（实际上不可能）\n",
    "            \n",
    "            mb_pred = model(mb_x, mb_x_len, mb_input, mb_y_len)\n",
    "            \n",
    "            mb_out_mask = torch.arange(mb_y_len.max().item(), device=device)[None, :] < mb_y_len[:, None]  \n",
    "            # [batch_size,最长句子的长度], 上面是bool类型， 下面是float类型， 只计算每个句子的有效部分， 填充的那部分去掉\n",
    "            mb_out_mask = mb_out_mask.float()  # [batch_size, seq_len-1]  因为mb_y_len.max()就是seq_len-1\n",
    "            \n",
    "            loss = loss_fn(mb_pred, mb_output, mb_out_mask)\n",
    "            \n",
    "            num_words = torch.sum(mb_y_len).item()\n",
    "            total_loss += loss.item() * num_words\n",
    "            total_num_words += num_words\n",
    "            \n",
    "    #print('Validation loss', total_loss / total_num_words)\n",
    "    val_loss = total_loss / total_num_words;\n",
    "    val_losses.append(val_loss)\n",
    "    return val_loss\n",
    "\n",
    "def train(model, data, num_epochs, patience):\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        total_num_words = total_loss = 0.\n",
    "        for it, (mb_x, mb_x_len, mb_y, mb_y_len) in enumerate(data):\n",
    "            mb_x = torch.from_numpy(mb_x).to(device).long()\n",
    "            mb_x_len = torch.from_numpy(mb_x_len).to(device).long()\n",
    "            mb_input = torch.from_numpy(mb_y[:, :-1]).to(device).long()\n",
    "            mb_output = torch.from_numpy(mb_y[:, 1:]).to(device).long()\n",
    "            mb_y_len = torch.from_numpy(mb_y_len-1).to(device).long()\n",
    "            mb_y_len[mb_y_len<=0] = 1\n",
    "            \n",
    "            mb_pred = model(mb_x, mb_x_len, mb_input, mb_y_len)\n",
    "            \n",
    "            mb_out_mask = torch.arange(mb_y_len.max().item(), device=device)[None, :] < mb_y_len[:, None]\n",
    "            mb_out_mask = mb_out_mask.float()\n",
    "            \n",
    "            loss = loss_fn(mb_pred, mb_output, mb_out_mask)\n",
    "            \n",
    "            num_words = torch.sum(mb_y_len).item()\n",
    "            total_loss += loss.item() * num_words\n",
    "            total_num_words += num_words\n",
    "            \n",
    "            # 更新\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.)     # 防止梯度爆炸\n",
    "            optimizer.step()\n",
    "            \n",
    "            #if it % 100 == 0:\n",
    "            #   print('Epoch', epoch, 'iteration', it, 'loss', loss.item())\n",
    "       \n",
    "        #print('Epoch', epoch, 'Training loss', total_loss / total_num_words)\n",
    "        trainingloss = total_loss / total_num_words;\n",
    "        train_losses.append(trainingloss)\n",
    "        #if epoch % 5 == 0:\n",
    "        val_loss=evaluate(model, dev_data)\n",
    "        \n",
    "        epoch_len = len(str(num_epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {trainingloss:.5f} ' +\n",
    "                     f'valid_loss: {val_loss:.5f}')\n",
    "        \n",
    "        print(print_msg)\n",
    "        \n",
    "        early_stopping(val_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "            \n",
    "train(model, train_data, num_epochs=50, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c007c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# epoch = range(num_epochs)\n",
    "# fig, ax = plt.subplots()\n",
    "# plt.plot(epoch, train_losses, 'g', label='Training loss')\n",
    "# plt.plot(epoch, val_losses, 'b', label='Validation loss')\n",
    "# plt.title('Training and Validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# ax.set_xticks(epoch)\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    " # visualize the loss as the network trained\n",
    "fig = plt.figure()\n",
    "plt.plot(range(1,len(train_losses)+1),train_losses, label='Training Loss')\n",
    "plt.plot(range(1,len(val_losses)+1),val_losses,label='Validation Loss')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "minposs = val_losses.index(min(val_losses))+1 \n",
    "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "#plt.ylim(1, 5) # consistent scale\n",
    "plt.xlim(0, len(train_losses)+1) # consistent scale\n",
    "#plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.title('Training and Validation loss')\n",
    "plt.show()\n",
    "fig.savefig('loss_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c99a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_dev(i):\n",
    "    text = \" \".join([int_to_vocab[w] for w in text_val[i]])\n",
    "    print(text)\n",
    "    summary = \" \".join([int_to_vocab[w] for w in summ_val[i]])\n",
    "    print(summary)\n",
    "\n",
    "    mb_x = torch.from_numpy(np.array(text_val[i]).reshape(1,-1)).long().to(device)\n",
    "    mb_x_len = torch.from_numpy(np.array([len(text_val[i])])).long().to(device)\n",
    "    # mb_y = torch.from_numpy(summ_val[i].reshape(1,-1)).long().to(device)\n",
    "    # mb_y_len = torch.from_numpy([len(summ_val[i])]).long().to(device)\n",
    "    bos = torch.Tensor([[vocab_to_int[\"<GO>\"]]]).long().to(device)\n",
    "    # 翻译时decoder的输入序列bos： [<GO>的index] \n",
    "    translation = model.translate(mb_x,mb_x_len, bos)\n",
    "    translation = [int_to_vocab[i] for i in translation.data.cpu().numpy().reshape(-1)]\n",
    "    trans = []\n",
    "    for word in translation:\n",
    "        if word !=\"<EOS>\":\n",
    "            trans.append(word)\n",
    "        else:\n",
    "            break\n",
    "    print(\" \".join(trans))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bda18b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO> get large bags 3 dollars walmart 3 50 stop shop selling 5 dollars bag um thanks love though addicted buy target walmart youe grocery store though <EOS>\n",
      "<GO> bad deal <EOS>\n",
      "love these\n",
      "\n",
      "<GO> ordered product parents send denmark cost lot shipping fees upon arrival left disappointed <br ><br >the product trolli brand gummy worms rather gift shop type knock furthermore trolli sold store contain gluten celiac disease made obsolete <br ><br >in defense could old <UNK> brand worms used would old looked new taste consistency normal trolli worms <EOS>\n",
      "<GO> not as advertised <EOS>\n",
      "not as good as the original\n",
      "\n",
      "<GO> babies sour albeit sour coating disappears quickly leaving sweet lemon drop first time put one mouth think put hair chest expecting sour taste never tasted something quite sour another reviewer stated candies great surprising others given watched guests spit across room expecting initial sour bite even surprisingly addictive get local japanese grocery much cheaper amazon offers even shipping costs like sour bitter lemon candies ones chemical aftertaste <EOS>\n",
      "<GO> get ready to pucker <EOS>\n",
      "not a fan\n",
      "\n",
      "<GO> package arrived promptly contents excellent condition product tasty though slight bit peppery taste tried varieties like one texas bbq best mesquite also good much milder texture right would know meat blind taste test little wet jerky makes tad messy packet contains whopping 10 grams protein lot nutrition small lightweight packet ideal camping keeping car glovebox briefcase bag etc times need boost pepper would given 5 stars rate 4 stars enjoy <EOS>\n",
      "<GO> spirited jerky product <EOS>\n",
      "spirited jerky\n",
      "\n",
      "<GO> product quaker oatmeal express golden brown sugar fantastic even tastes better regular instant oatmeal packet maple brown sugar recommend anyone try guarantee love oatmeal <EOS>\n",
      "<GO> best on the go oatmeal <EOS>\n",
      "oatmeal\n",
      "\n",
      "<GO> love cider year round bought back summer cups iced cider found cider k cups add sugar make sweet enough drink seemed like brand tried made apple flavored tea cider love product right amount sweetness recently made splash rum yummy results <EOS>\n",
      "<GO> love it <EOS>\n",
      "love it\n",
      "\n",
      "<GO> american staffordshire aka pitbull 1 years old needs pretty tough toys loves toy 3rd nylabone toy really done much damage tell one far favorite <EOS>\n",
      "<GO> my pitbull loves it <EOS>\n",
      "my dog loves these\n",
      "\n",
      "<GO> searched searched food would meet dog nutritional needs well address issues allergies food totally answer us near expensive one vet wanted put loves love makes everyone happy <EOS>\n",
      "<GO> wonderful dog food <EOS>\n",
      "great dog food\n",
      "\n",
      "<GO> wow cannot believe threw stuff wasted money going ask refund amazon feel usda approved misleading <br ><br >this stuff stinks badly take trash tossed also hugely disappointed see product bolivia <br ><br >i looking nice organic usa grown freeze dried fruit saw usda approved assumed made usa says right label product bolivia <br ><br >if looking good snack strongly suggest checking <EOS>\n",
      "<GO> disgusting smells made in bolivia <EOS>\n",
      "this product is not the product\n",
      "\n",
      "<GO> love sweetened tea packaging found years ago fell love control strength sweetness looked high low stores finally amazon regularly ship please amazon keep stock <EOS>\n",
      "<GO> i love this citrus green tea <EOS>\n",
      "love this tea\n",
      "\n",
      "<GO> bought bulk animal rescue donation drive add care package returning immediately saw produced china realize time would never bought mean discriminate still leery buying pet products made china given extremely poor dangerous quality control bought three flavors chicken flavor particular gives pause bright almost neon yellow going back asap <EOS>\n",
      "<GO> made in china <EOS>\n",
      "do not buy this\n",
      "\n",
      "<GO> generally coffee drinker drink herbal tea late evenings going bed found smooth flavored tea medium body great blend touch orange flavor correct amount bergamot makes tea unique really enjoyed delicious cup tea <br ><br >1 <EOS>\n",
      "<GO> delicious tea <EOS>\n",
      "the best tea for tea lovers\n",
      "\n",
      "<GO> glad find amazon looking quite time success never thought look <br <UNK> flay uses frequently wanted try well pleased results adds another depth flavor others said careful use much powerful thicken quite alot <EOS>\n",
      "<GO> great product <EOS>\n",
      "not a dark\n",
      "\n",
      "<GO> billy bites banana nut bread die wonderful flavor moist perfect consistency able resist bread think stop one slice either would make great gifts <EOS>\n",
      "<GO> a b s o l u t e l y awesome <EOS>\n",
      "banana bread\n",
      "\n",
      "<GO> use syrup create coffee beanery signature drink caf eacute carmel perfect ounce two syrup 12 oz coffee use keurig caribou blend top whipped cream sprinkles shave ghirardelli delicious savings <EOS>\n",
      "<GO> ave coffee dollar <EOS>\n",
      "perfect for coffee lovers\n",
      "\n",
      "<GO> taste amazing bitter best espresso coffee tried still tried illy though would definitely reccomend anyone loves good strong cup coffee well worth money <EOS>\n",
      "<GO> best i have tried <EOS>\n",
      "best i have tried\n",
      "\n",
      "<GO> like others said consistency stage 2 combo thin could thickened oatmeal cereal 7 mth old loved flavor impatiently waited baby foods like contains spinach iron fruit antioxidants sweeten bit would use everyday home somewhat costly per pouch terrific option travel need something easy hand feed baby tried squeezing contents pouch mouth particularly like think used fed spoon older baby could squeeze eat find without spoon great option <EOS>\n",
      "<GO> baby loved it convenient pouch <EOS>\n",
      "baby liked it\n",
      "\n",
      "<GO> rice way better ordinary rice see supermarkets uncle ben rice roni etc <br > live planning buy warning good stop kind rice great <EOS>\n",
      "<GO> perfect taste <EOS>\n",
      "rice\n",
      "\n",
      "<GO> flavor reminds kool aid vitamin water flavor sweet light sense overly syrup mind artificial sweetener flavors issue notice bad aftertaste feel like plain water using cheaper buying separate bottles flavored water <EOS>\n",
      "<GO> like kool aid but easier <EOS>\n",
      "not the best\n",
      "\n",
      "<GO> excellent product received record time thanks good job taste perfect consistency thing question much plastic wasted container less half full time ever received product container half size slightly larger considered stop waste excess plastic may end landfills recycled wrote company three years ago asked would consider package modification never acknowledged <EOS>\n",
      "<GO> stevia <EOS>\n",
      "stevia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(110,130):\n",
    "    translate_dev(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3522ab69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO> dried blue berry little chewy taste great add special k morning talk great bm fact eat much well never mind dont east much without eating bunch cheese afterwards <EOS>\n",
      "<GO> tastes great <EOS>\n",
      "great for diabetics\n"
     ]
    }
   ],
   "source": [
    "translate_dev(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), '\\\\Users\\\\SWong7923\\\\PycharmProjects\\\\pythonProject2\\\\model\\\\checkpoint.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('\\\\Users\\\\SWong7923\\\\PycharmProjects\\\\pythonProject2\\\\checkpoint.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
